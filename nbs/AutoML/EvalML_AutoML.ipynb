{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-24 07:00:13,268 featuretools - WARNING    Featuretools failed to load plugin nlp_primitives from library nlp_primitives. For a full stack trace, set logging to debug.\n"
     ]
    }
   ],
   "source": [
    "import evalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml import AutoMLSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datatable as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = urlopen('https://featurelabs-static.s3.amazonaws.com/spam_text_messages_modified.csv')\n",
    "data = pd.read_csv(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Table check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datatable.Frame"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_dt = dt.fread(r'C:\\my-drive\\git-repos\\my-learning\\my_ml_learning\\data\\Salary_Data.csv')\n",
    "type(df_to_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>YearsExperience</th><th>Age</th><th>Salary</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>1.1</td><td>21</td><td>39343</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>1.3</td><td>21.5</td><td>46205</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>2 rows &times; 3 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#269316882a0 2x3>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_dt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2989, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1     spam  FreeMsg Hey there darling it's been 3 week's n..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     2242\n",
       "spam     747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X, y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Category', axis=1)\n",
    "y = data.Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "2  WINNER!! As a valued network customer you have...\n",
       "3  Had your mobile 11 months or more? U R entitle...\n",
       "4  SIX chances to win CASH! From 100 to 20,000 po..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    spam\n",
       "1    spam\n",
       "2    spam\n",
       "3    spam\n",
       "4    spam\n",
       "Name: Category, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ProblemTypes.BINARY: 'binary'>,\n",
       " <ProblemTypes.MULTICLASS: 'multiclass'>,\n",
       " <ProblemTypes.REGRESSION: 'regression'>,\n",
       " <ProblemTypes.TIME_SERIES_REGRESSION: 'time series regression'>,\n",
       " <ProblemTypes.TIME_SERIES_BINARY: 'time series binary'>,\n",
       " <ProblemTypes.TIME_SERIES_MULTICLASS: 'time series multiclass'>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalml.problem_types.ProblemTypes.all_problem_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type=evalml.problem_types.ProblemTypes.BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Haha I heard that, text me when you're around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>I'm thinking that chennai forgot to come for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Can you tell Shola to please go to college of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>K k pa Had your lunch aha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Double your mins &amp; txts on Orange or 1/2 price...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>K:)eng rocking in ashes:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>Hello. Sort of out in town already. That . So ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>We are hoping to get away by 7, from Langport....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>Maybe you should find something else to do ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2391 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Message\n",
       "562       Haha I heard that, text me when you're around\n",
       "1253  I'm thinking that chennai forgot to come for a...\n",
       "1816  Can you tell Shola to please go to college of ...\n",
       "2054                         K k pa Had your lunch aha.\n",
       "511   staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323\n",
       "...                                                 ...\n",
       "326   Double your mins & txts on Orange or 1/2 price...\n",
       "2149                          K:)eng rocking in ashes:)\n",
       "1406  Hello. Sort of out in town already. That . So ...\n",
       "1068  We are hoping to get away by 7, from Langport....\n",
       "2268  Maybe you should find something else to do ins...\n",
       "\n",
       "[2391 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do AutoML Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mAutoMLSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mproblem_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdata_splitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mallowed_component_graphs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mallowed_model_families\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstart_iteration_callback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0madd_result_callback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0merror_callback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0madditional_objectives\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0malternate_thresholding_objective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtuner_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moptimize_thresholds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mensembling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_batches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mproblem_configuration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtrain_best_pipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpipeline_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcustom_hyperparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msampler_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msampler_balanced_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mallow_long_running_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_ensembling_split_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_pipelines_per_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_automl_algorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'iterative'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sequential'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Automated Pipeline search.\n",
      "\n",
      "Args:\n",
      "    X_train (pd.DataFrame): The input training data of shape [n_samples, n_features]. Required.\n",
      "\n",
      "    y_train (pd.Series): The target training data of length [n_samples]. Required for supervised learning tasks.\n",
      "\n",
      "    problem_type (str or ProblemTypes): Type of supervised learning problem. See evalml.problem_types.ProblemType.all_problem_types for a full list.\n",
      "\n",
      "    objective (str, ObjectiveBase): The objective to optimize for. Used to propose and rank pipelines, but not for optimizing each pipeline during fit-time.\n",
      "        When set to 'auto', chooses:\n",
      "        - LogLossBinary for binary classification problems,\n",
      "        - LogLossMulticlass for multiclass classification problems, and\n",
      "        - R2 for regression problems.\n",
      "\n",
      "    max_iterations (int): Maximum number of iterations to search. If max_iterations and\n",
      "        max_time is not set, then max_iterations will default to max_iterations of 5.\n",
      "\n",
      "    max_time (int, str): Maximum time to search for pipelines.\n",
      "        This will not start a new pipeline search after the duration\n",
      "        has elapsed. If it is an integer, then the time will be in seconds.\n",
      "        For strings, time can be specified as seconds, minutes, or hours.\n",
      "\n",
      "    patience (int): Number of iterations without improvement to stop search early. Must be positive.\n",
      "        If None, early stopping is disabled. Defaults to None.\n",
      "\n",
      "    tolerance (float): Minimum percentage difference to qualify as score improvement for early stopping.\n",
      "        Only applicable if patience is not None. Defaults to None.\n",
      "\n",
      "    allowed_component_graphs (dict): A dictionary of lists or ComponentGraphs indicating the component graphs allowed in the search.\n",
      "        The format should follow { \"Name_0\": [list_of_components], \"Name_1\": ComponentGraph(...) }\n",
      "\n",
      "        The default of None indicates all pipeline component graphs for this problem type are allowed. Setting this field will cause\n",
      "        allowed_model_families to be ignored.\n",
      "\n",
      "        e.g. allowed_component_graphs = { \"My_Graph\": [\"Imputer\", \"One Hot Encoder\", \"Random Forest Classifier\"] }\n",
      "\n",
      "    allowed_model_families (list(str, ModelFamily)): The model families to search. The default of None searches over all\n",
      "        model families. Run evalml.pipelines.components.utils.allowed_model_families(\"binary\") to see options. Change `binary`\n",
      "        to `multiclass` or `regression` depending on the problem type. Note that if allowed_pipelines is provided,\n",
      "        this parameter will be ignored.\n",
      "\n",
      "    data_splitter (sklearn.model_selection.BaseCrossValidator): Data splitting method to use. Defaults to StratifiedKFold.\n",
      "\n",
      "    tuner_class: The tuner class to use. Defaults to SKOptTuner.\n",
      "\n",
      "    optimize_thresholds (bool): Whether or not to optimize the binary pipeline threshold. Defaults to True.\n",
      "\n",
      "    start_iteration_callback (callable): Function called before each pipeline training iteration.\n",
      "        Callback function takes three positional parameters: The pipeline instance and the AutoMLSearch object.\n",
      "\n",
      "    add_result_callback (callable): Function called after each pipeline training iteration.\n",
      "        Callback function takes three positional parameters: A dictionary containing the training results for the new pipeline, an untrained_pipeline containing the parameters used during training, and the AutoMLSearch object.\n",
      "\n",
      "    error_callback (callable): Function called when `search()` errors and raises an Exception.\n",
      "        Callback function takes three positional parameters: the Exception raised, the traceback, and the AutoMLSearch object.\n",
      "        Must also accepts kwargs, so AutoMLSearch is able to pass along other appropriate parameters by default.\n",
      "        Defaults to None, which will call `log_error_callback`.\n",
      "\n",
      "    additional_objectives (list): Custom set of objectives to score on.\n",
      "        Will override default objectives for problem type if not empty.\n",
      "\n",
      "    alternate_thresholding_objective (str): The objective to use for thresholding binary classification pipelines if the main objective provided isn't tuneable.\n",
      "        Defaults to F1.\n",
      "\n",
      "    random_seed (int): Seed for the random number generator. Defaults to 0.\n",
      "\n",
      "    n_jobs (int or None): Non-negative integer describing level of parallelism used for pipelines.\n",
      "        None and 1 are equivalent. If set to -1, all CPUs are used. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used.\n",
      "\n",
      "    ensembling (boolean): If True, runs ensembling in a separate batch after every allowed pipeline class has been iterated over.\n",
      "        If the number of unique pipelines to search over per batch is one, ensembling will not run. Defaults to False.\n",
      "\n",
      "    max_batches (int): The maximum number of batches of pipelines to search. Parameters max_time, and\n",
      "        max_iterations have precedence over stopping the search.\n",
      "\n",
      "    problem_configuration (dict, None): Additional parameters needed to configure the search. For example,\n",
      "        in time series problems, values should be passed in for the date_index, gap, forecast_horizon, and max_delay variables.\n",
      "\n",
      "    train_best_pipeline (boolean): Whether or not to train the best pipeline before returning it. Defaults to True.\n",
      "\n",
      "    pipeline_parameters (dict): A dict of the parameters used to initialize a pipeline with.\n",
      "        Keys should consist of the component names and values should specify parameter values\n",
      "\n",
      "        e.g. pipeline_parameters = { 'Imputer' : { 'numeric_impute_strategy': 'most_frequent' } }\n",
      "\n",
      "    custom_hyperparameters (dict): A dict of the hyperparameter ranges used to iterate over during search.\n",
      "        Keys should consist of the component names and values should specify a singular value or skopt.Space.\n",
      "\n",
      "        e.g. custom_hyperparameters = { 'Imputer' : { 'numeric_impute_strategy': Categorical(['most_frequent', 'median']) } }\n",
      "\n",
      "    sampler_method (str): The data sampling component to use in the pipelines if the problem type is classification and the target balance is smaller than the sampler_balanced_ratio.\n",
      "        Either 'auto', which will use our preferred sampler for the data, 'Undersampler', 'Oversampler', or None. Defaults to 'auto'.\n",
      "\n",
      "    sampler_balanced_ratio (float): The minority:majority class ratio that we consider balanced, so a 1:4 ratio would be equal to 0.25. If the class balance is larger than this provided value,\n",
      "        then we will not add a sampler since the data is then considered balanced. Overrides the `sampler_ratio` of the samplers. Defaults to 0.25.\n",
      "\n",
      "    allow_long_running_models (bool): Whether or not to allow longer-running models for large multiclass problems. If False and no pipelines, component graphs, or model families are provided,\n",
      "        AutoMLSearch will not use Elastic Net or XGBoost when there are more than 75 multiclass targets and will not use CatBoost when there are more than 150 multiclass targets. Defaults to False.\n",
      "\n",
      "    _ensembling_split_size (float): The amount of the training data we'll set aside for training ensemble metalearners. Only used when ensembling is True.\n",
      "        Must be between 0 and 1, exclusive. Defaults to 0.2\n",
      "\n",
      "    _pipelines_per_batch (int): The number of pipelines to train for every batch after the first one.\n",
      "        The first batch will train a baseline pipline + one of each pipeline family allowed in the search.\n",
      "\n",
      "    _automl_algorithm (str): The automl algorithm to use. Currently the two choices are 'iterative' and 'default'. Defaults to `iterative`.\n",
      "\n",
      "    engine (EngineBase or str): The engine instance used to evaluate pipelines. Dask or concurrent.futures engines can also\n",
      "        be chosen by providing a string from the list [\"sequential\", \"cf_threaded\", \"cf_process\", \"dask_threaded\", \"dask_process\"].\n",
      "        If a parallel engine is selected this way, the maximum amount of parallelism, as determined by the engine, will be used. Defaults to \"sequential\".\n",
      "\n",
      "    verbose (boolean): Whether or not to display semi-real-time updates to stdout while search is running. Defaults to False.\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\595244\\anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\automl_search.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "?AutoMLSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary', max_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tElastic Net Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 0: Encountered an error.\n",
      "\t\t\tElastic Net Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 0: All scores will be replaced with nan.\n",
      "\t\t\tFold 0: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 0: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Elastic Net Classifier': {'penalty': 'elasticnet', 'C': 1.0, 'l1_ratio': 0.15, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'saga'}}\n",
      "\t\t\tFold 0: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 400, in _transform_features\n",
      "    output = component_instance.fit_transform(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\transformers\\scalers\\standard_scaler.py\", line 63, in fit_transform\n",
      "    return self.fit(X, y).transform(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\component_base.py\", line 135, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 667, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 698, in partial_fit\n",
      "    force_all_finite='allow-nan')\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 420, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tElastic Net Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 1: Encountered an error.\n",
      "\t\t\tElastic Net Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 1: All scores will be replaced with nan.\n",
      "\t\t\tFold 1: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 1: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Elastic Net Classifier': {'penalty': 'elasticnet', 'C': 1.0, 'l1_ratio': 0.15, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'saga'}}\n",
      "\t\t\tFold 1: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 400, in _transform_features\n",
      "    output = component_instance.fit_transform(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\transformers\\scalers\\standard_scaler.py\", line 63, in fit_transform\n",
      "    return self.fit(X, y).transform(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\component_base.py\", line 135, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 667, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 698, in partial_fit\n",
      "    force_all_finite='allow-nan')\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 420, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tElastic Net Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 2: Encountered an error.\n",
      "\t\t\tElastic Net Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 2: All scores will be replaced with nan.\n",
      "\t\t\tFold 2: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 2: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Elastic Net Classifier': {'penalty': 'elasticnet', 'C': 1.0, 'l1_ratio': 0.15, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'saga'}}\n",
      "\t\t\tFold 2: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 400, in _transform_features\n",
      "    output = component_instance.fit_transform(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\transformers\\scalers\\standard_scaler.py\", line 63, in fit_transform\n",
      "    return self.fit(X, y).transform(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\component_base.py\", line 135, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 667, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 698, in partial_fit\n",
      "    force_all_finite='allow-nan')\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 420, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tLogistic Regression Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 0: Encountered an error.\n",
      "\t\t\tLogistic Regression Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 0: All scores will be replaced with nan.\n",
      "\t\t\tFold 0: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 0: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Logistic Regression Classifier': {'penalty': 'l2', 'C': 1.0, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'lbfgs'}}\n",
      "\t\t\tFold 0: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 400, in _transform_features\n",
      "    output = component_instance.fit_transform(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\transformers\\scalers\\standard_scaler.py\", line 63, in fit_transform\n",
      "    return self.fit(X, y).transform(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\component_base.py\", line 135, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 667, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 698, in partial_fit\n",
      "    force_all_finite='allow-nan')\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 420, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tLogistic Regression Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 1: Encountered an error.\n",
      "\t\t\tLogistic Regression Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 1: All scores will be replaced with nan.\n",
      "\t\t\tFold 1: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 1: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Logistic Regression Classifier': {'penalty': 'l2', 'C': 1.0, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'lbfgs'}}\n",
      "\t\t\tFold 1: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 400, in _transform_features\n",
      "    output = component_instance.fit_transform(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\transformers\\scalers\\standard_scaler.py\", line 63, in fit_transform\n",
      "    return self.fit(X, y).transform(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\component_base.py\", line 135, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 667, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 698, in partial_fit\n",
      "    force_all_finite='allow-nan')\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 420, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tLogistic Regression Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 2: Encountered an error.\n",
      "\t\t\tLogistic Regression Classifier w/ Label Encoder + Drop Columns Transformer + Standard Scaler fold 2: All scores will be replaced with nan.\n",
      "\t\t\tFold 2: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 2: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Logistic Regression Classifier': {'penalty': 'l2', 'C': 1.0, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'lbfgs'}}\n",
      "\t\t\tFold 2: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 400, in _transform_features\n",
      "    output = component_instance.fit_transform(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\transformers\\scalers\\standard_scaler.py\", line 63, in fit_transform\n",
      "    return self.fit(X, y).transform(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\component_base.py\", line 135, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 667, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py\", line 698, in partial_fit\n",
      "    force_all_finite='allow-nan')\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 420, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tXGBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 0: Encountered an error.\n",
      "\t\t\tXGBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 0: All scores will be replaced with nan.\n",
      "\t\t\tFold 0: Exception during automl search: [08:33:27] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:506: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "\t\t\tFold 0: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'XGBoost Classifier': {'eta': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'n_jobs': -1, 'eval_metric': 'logloss'}}\n",
      "\t\t\tFold 0: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\classifiers\\xgboost_classifier.py\", line 124, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py\", line 824, in fit\n",
      "    callbacks=callbacks)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\training.py\", line 212, in train\n",
      "    xgb_model=xgb_model, callbacks=callbacks)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\training.py\", line 75, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\", line 1369, in update\n",
      "    dtrain.handle))\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\", line 190, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\n",
      "\t\t\tXGBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 1: Encountered an error.\n",
      "\t\t\tXGBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 1: All scores will be replaced with nan.\n",
      "\t\t\tFold 1: Exception during automl search: [08:33:27] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:506: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "\t\t\tFold 1: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'XGBoost Classifier': {'eta': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'n_jobs': -1, 'eval_metric': 'logloss'}}\n",
      "\t\t\tFold 1: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\classifiers\\xgboost_classifier.py\", line 124, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py\", line 824, in fit\n",
      "    callbacks=callbacks)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\training.py\", line 212, in train\n",
      "    xgb_model=xgb_model, callbacks=callbacks)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\training.py\", line 75, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\", line 1369, in update\n",
      "    dtrain.handle))\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\", line 190, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\n",
      "\t\t\tXGBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 2: Encountered an error.\n",
      "\t\t\tXGBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 2: All scores will be replaced with nan.\n",
      "\t\t\tFold 2: Exception during automl search: [08:33:27] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:506: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "\t\t\tFold 2: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'XGBoost Classifier': {'eta': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'n_jobs': -1, 'eval_metric': 'logloss'}}\n",
      "\t\t\tFold 2: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\classifiers\\xgboost_classifier.py\", line 124, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py\", line 824, in fit\n",
      "    callbacks=callbacks)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\training.py\", line 212, in train\n",
      "    xgb_model=xgb_model, callbacks=callbacks)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\training.py\", line 75, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\", line 1369, in update\n",
      "    dtrain.handle))\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\", line 190, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\n",
      "\t\t\tCatBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 0: Encountered an error.\n",
      "\t\t\tCatBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 0: All scores will be replaced with nan.\n",
      "\t\t\tFold 0: Exception during automl search: Input data must have at least one feature\n",
      "\t\t\tFold 0: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'CatBoost Classifier': {'n_estimators': 10, 'eta': 0.03, 'max_depth': 6, 'bootstrap_type': None, 'silent': True, 'allow_writing_files': False, 'n_jobs': -1}}\n",
      "\t\t\tFold 0: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\classifiers\\catboost_classifier.py\", line 120, in fit\n",
      "    self._component_obj.fit(X, y, silent=True, cat_features=cat_cols)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 4718, in fit\n",
      "    silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 2029, in _fit\n",
      "    callbacks=callbacks\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 1909, in _prepare_train_params\n",
      "    baseline, column_description)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 1190, in _build_train_pool\n",
      "    group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 564, in __init__\n",
      "    self._check_data_empty(data)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 722, in _check_data_empty\n",
      "    raise CatBoostError(\"Input data must have at least one feature\")\n",
      "\n",
      "\t\t\tCatBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 1: Encountered an error.\n",
      "\t\t\tCatBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 1: All scores will be replaced with nan.\n",
      "\t\t\tFold 1: Exception during automl search: Input data must have at least one feature\n",
      "\t\t\tFold 1: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'CatBoost Classifier': {'n_estimators': 10, 'eta': 0.03, 'max_depth': 6, 'bootstrap_type': None, 'silent': True, 'allow_writing_files': False, 'n_jobs': -1}}\n",
      "\t\t\tFold 1: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\classifiers\\catboost_classifier.py\", line 120, in fit\n",
      "    self._component_obj.fit(X, y, silent=True, cat_features=cat_cols)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 4718, in fit\n",
      "    silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 2029, in _fit\n",
      "    callbacks=callbacks\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 1909, in _prepare_train_params\n",
      "    baseline, column_description)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 1190, in _build_train_pool\n",
      "    group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 564, in __init__\n",
      "    self._check_data_empty(data)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 722, in _check_data_empty\n",
      "    raise CatBoostError(\"Input data must have at least one feature\")\n",
      "\n",
      "\t\t\tCatBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 2: Encountered an error.\n",
      "\t\t\tCatBoost Classifier w/ Label Encoder + Drop Columns Transformer fold 2: All scores will be replaced with nan.\n",
      "\t\t\tFold 2: Exception during automl search: Input data must have at least one feature\n",
      "\t\t\tFold 2: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'CatBoost Classifier': {'n_estimators': 10, 'eta': 0.03, 'max_depth': 6, 'bootstrap_type': None, 'silent': True, 'allow_writing_files': False, 'n_jobs': -1}}\n",
      "\t\t\tFold 2: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\classifiers\\catboost_classifier.py\", line 120, in fit\n",
      "    self._component_obj.fit(X, y, silent=True, cat_features=cat_cols)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 4718, in fit\n",
      "    silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 2029, in _fit\n",
      "    callbacks=callbacks\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 1909, in _prepare_train_params\n",
      "    baseline, column_description)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 1190, in _build_train_pool\n",
      "    group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 564, in __init__\n",
      "    self._check_data_empty(data)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\catboost\\core.py\", line 722, in _check_data_empty\n",
      "    raise CatBoostError(\"Input data must have at least one feature\")\n",
      "\n",
      "\t\t\tRandom Forest Classifier w/ Label Encoder + Drop Columns Transformer fold 0: Encountered an error.\n",
      "\t\t\tRandom Forest Classifier w/ Label Encoder + Drop Columns Transformer fold 0: All scores will be replaced with nan.\n",
      "\t\t\tFold 0: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 0: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Random Forest Classifier': {'n_estimators': 100, 'max_depth': 6, 'n_jobs': -1}}\n",
      "\t\t\tFold 0: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    accept_sparse=\"csc\", dtype=DTYPE)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 803, in check_X_y\n",
      "    estimator=estimator)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tRandom Forest Classifier w/ Label Encoder + Drop Columns Transformer fold 1: Encountered an error.\n",
      "\t\t\tRandom Forest Classifier w/ Label Encoder + Drop Columns Transformer fold 1: All scores will be replaced with nan.\n",
      "\t\t\tFold 1: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 1: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Random Forest Classifier': {'n_estimators': 100, 'max_depth': 6, 'n_jobs': -1}}\n",
      "\t\t\tFold 1: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    accept_sparse=\"csc\", dtype=DTYPE)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 803, in check_X_y\n",
      "    estimator=estimator)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tRandom Forest Classifier w/ Label Encoder + Drop Columns Transformer fold 2: Encountered an error.\n",
      "\t\t\tRandom Forest Classifier w/ Label Encoder + Drop Columns Transformer fold 2: All scores will be replaced with nan.\n",
      "\t\t\tFold 2: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 2: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Random Forest Classifier': {'n_estimators': 100, 'max_depth': 6, 'n_jobs': -1}}\n",
      "\t\t\tFold 2: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    accept_sparse=\"csc\", dtype=DTYPE)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 803, in check_X_y\n",
      "    estimator=estimator)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tDecision Tree Classifier w/ Label Encoder + Drop Columns Transformer fold 0: Encountered an error.\n",
      "\t\t\tDecision Tree Classifier w/ Label Encoder + Drop Columns Transformer fold 0: All scores will be replaced with nan.\n",
      "\t\t\tFold 0: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 0: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Decision Tree Classifier': {'criterion': 'gini', 'max_features': 'auto', 'max_depth': 6, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}}\n",
      "\t\t\tFold 0: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\tree\\_classes.py\", line 158, in fit\n",
      "    check_y_params))\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 429, in _validate_data\n",
      "    X = check_array(X, **check_X_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tDecision Tree Classifier w/ Label Encoder + Drop Columns Transformer fold 1: Encountered an error.\n",
      "\t\t\tDecision Tree Classifier w/ Label Encoder + Drop Columns Transformer fold 1: All scores will be replaced with nan.\n",
      "\t\t\tFold 1: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 1: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Decision Tree Classifier': {'criterion': 'gini', 'max_features': 'auto', 'max_depth': 6, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}}\n",
      "\t\t\tFold 1: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\tree\\_classes.py\", line 158, in fit\n",
      "    check_y_params))\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 429, in _validate_data\n",
      "    X = check_array(X, **check_X_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tDecision Tree Classifier w/ Label Encoder + Drop Columns Transformer fold 2: Encountered an error.\n",
      "\t\t\tDecision Tree Classifier w/ Label Encoder + Drop Columns Transformer fold 2: All scores will be replaced with nan.\n",
      "\t\t\tFold 2: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 2: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Decision Tree Classifier': {'criterion': 'gini', 'max_features': 'auto', 'max_depth': 6, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}}\n",
      "\t\t\tFold 2: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\tree\\_classes.py\", line 158, in fit\n",
      "    check_y_params))\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 429, in _validate_data\n",
      "    X = check_array(X, **check_X_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tExtra Trees Classifier w/ Label Encoder + Drop Columns Transformer fold 0: Encountered an error.\n",
      "\t\t\tExtra Trees Classifier w/ Label Encoder + Drop Columns Transformer fold 0: All scores will be replaced with nan.\n",
      "\t\t\tFold 0: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 0: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Extra Trees Classifier': {'n_estimators': 100, 'max_features': 'auto', 'max_depth': 6, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1}}\n",
      "\t\t\tFold 0: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    accept_sparse=\"csc\", dtype=DTYPE)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 803, in check_X_y\n",
      "    estimator=estimator)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tExtra Trees Classifier w/ Label Encoder + Drop Columns Transformer fold 1: Encountered an error.\n",
      "\t\t\tExtra Trees Classifier w/ Label Encoder + Drop Columns Transformer fold 1: All scores will be replaced with nan.\n",
      "\t\t\tFold 1: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 1: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Extra Trees Classifier': {'n_estimators': 100, 'max_features': 'auto', 'max_depth': 6, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1}}\n",
      "\t\t\tFold 1: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    accept_sparse=\"csc\", dtype=DTYPE)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 803, in check_X_y\n",
      "    estimator=estimator)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n",
      "\t\t\tExtra Trees Classifier w/ Label Encoder + Drop Columns Transformer fold 2: Encountered an error.\n",
      "\t\t\tExtra Trees Classifier w/ Label Encoder + Drop Columns Transformer fold 2: All scores will be replaced with nan.\n",
      "\t\t\tFold 2: Exception during automl search: at least one array or dtype is required\n",
      "\t\t\tFold 2: Parameters:\n",
      "\t{'Drop Columns Transformer': {'columns': ['Message']}, 'Extra Trees Classifier': {'n_estimators': 100, 'max_features': 'auto', 'max_depth': 6, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1}}\n",
      "\t\t\tFold 2: Traceback:\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 208, in train_and_score_pipeline\n",
      "    pipeline, X_train, y_train, automl_config, schema=False\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\", line 136, in train_pipeline\n",
      "    cv_pipeline.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py\", line 56, in fit\n",
      "    self._fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py\", line 273, in _fit\n",
      "    self.component_graph.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 224, in fit\n",
      "    self._transform_features(self.compute_order, X, y, fit=True)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\component_graph.py\", line 418, in _transform_features\n",
      "    component_instance.fit(x_inputs, y_input)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\utils\\base_meta.py\", line 19, in _set_fit\n",
      "    return_value = method(self, X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\Anaconda3\\envs\\krish_env_new\\lib\\site-packages\\evalml\\pipelines\\components\\estimators\\estimator.py\", line 79, in fit\n",
      "    self._component_obj.fit(X, y)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    accept_sparse=\"csc\", dtype=DTYPE)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 803, in check_X_y\n",
      "    estimator=estimator)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "\n",
      "  File \"C:\\Users\\595244\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\", line 534, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in result_type\n",
      "\n"
     ]
    }
   ],
   "source": [
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61ea9aa73e02b58d53cb2ec6c42f910c12dcb2b185565d429cb0cdc896334cf8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('krish_env_new': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
